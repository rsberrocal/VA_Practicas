{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: Template matching and HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "## Descriptors extraction for object detection, based on template matching and HOG\n",
    "==============================================================================================\n",
    "\n",
    "In this tutorial we focus on the following main topics:\n",
    "\n",
    "1) Template matching\n",
    "   \n",
    "2) Image Descriptors: \"Sliding window\" and HOG image descriptor    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Template matching\n",
    "\n",
    "The match_template function from scikit-image uses fast, normalized cross-correlation [1] to find instances of the template in the image. Note that the peaks in the output of match_template correspond to the origin (i.e. top-left corner) of the template.\n",
    "\n",
    "[1] J. P. Lewis, “Fast Normalized Cross-Correlation”, Industrial Light and Magic.\n",
    "\n",
    "\n",
    "See an example in [coin exercise](http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_template.html#sphx-glr-auto-examples-features-detection-plot-template-py) in skimage.\n",
    " \n",
    "Don't forget to normalize the images (having pixel values between [0,1]) before comparing them.\n",
    "\n",
    "First exercise will claim to recognize a letter among letters of different fonts. For this purpose, let us read the image lettersA.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import match_template\n",
    "\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "\n",
    "# Load image\n",
    "image = io.imread('./images/lettersA.gif')\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('The dimensions of the image are: ', image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read an image \"A.png\" that will be the query image that is the template to look among the different letters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load template\n",
    "imgA = io.imread('./images/A.png')\n",
    "print('The dimensions of the image are: ', imgA.shape)\n",
    "\n",
    "imgA = rgb2gray(rgba2rgb(imgA)) \n",
    "\n",
    "\n",
    "#visualize\n",
    "plt.imshow(imgA, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('The dimensions of the image are: ', imgA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize\n",
    "def visualize2(tigre_f,tigre_x,label1,label2):\n",
    "    #visualize\n",
    "    fig=plt.figure(figsize=(15,15))\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.title(label1)\n",
    "    plt.imshow(tigre_f, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.title(label2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(tigre_x, cmap='gray')\n",
    "    \n",
    "def visualize3(tigre_f,tigre_x,tigre_xb,label1,label2,label3):\n",
    "    #visualize\n",
    "    fig=plt.figure(figsize=(15,15))\n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.title(label1)\n",
    "    plt.imshow(tigre_f, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.title(label2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(tigre_x, cmap='gray')\n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(label3)\n",
    "    plt.imshow(tigre_xb, cmap='gray')\n",
    "\n",
    "\n",
    "def visualize4(tigre1,tigre2,tigre3,tigre4,label1,label2,label3,label4):\n",
    "    #visualize\n",
    "    fig=plt.figure(figsize=(15,15))\n",
    "    fig.add_subplot(1,4,1)\n",
    "    plt.title(label1)\n",
    "    plt.imshow(tigre1, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    fig.add_subplot(1,4,2)\n",
    "    plt.title(label2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(tigre2, cmap='gray')\n",
    "    fig.add_subplot(1,4,3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(label3)\n",
    "    plt.imshow(tigre3, cmap='gray')\n",
    "    fig.add_subplot(1,4,4)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(label4)\n",
    "    plt.imshow(tigre4, cmap='gray')\n",
    "\n",
    "\n",
    "visualize2(image, imgA, 'all As', 'template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command [match_template()](https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_template.html) allows to match template using normalized cross-correlation. Check what is the output of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = match_template(image, imgA) # Uses normalized cross-correlation\n",
    "\n",
    "print(result.min(), result.max()) #why are we interested in the min and max?\n",
    "print(np.unique(result))\n",
    "\n",
    "visualize3(imgA, image, result, 'patron', 'todas las As', 'resultado de la cross-correlation normalizada')\n",
    "plt.imshow(result, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's take the position in the image of the maximum response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tm_results(result,imgTemp, image): \n",
    "    ij = np.unravel_index(np.argmax(result), result.shape)\n",
    "    x, y = ij[::-1]\n",
    "\n",
    "    #visualize it\n",
    "    fig = plt.figure(figsize=(16, 6))\n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    ax3 = plt.subplot(1, 3, 3)\n",
    "\n",
    "    ax1.imshow(imgTemp, cmap=plt.cm.gray)\n",
    "    ax1.set_axis_off()\n",
    "    ax1.set_title('Template')\n",
    "\n",
    "    ax2.imshow(image, cmap=plt.cm.gray)\n",
    "    ax2.set_axis_off()\n",
    "    ax2.set_title('Image')\n",
    "    # highlight matched region\n",
    "    himg, wimg = imgA.shape\n",
    "    rect = plt.Rectangle((x, y), wimg, himg, edgecolor='r', facecolor='none')\n",
    "    ax2.add_patch(rect)\n",
    "\n",
    "    ax3.imshow(result, cmap='gray')\n",
    "    ax3.set_axis_off()\n",
    "    ax3.set_title('Result of the `match_template`')\n",
    "    # highlight matched region\n",
    "    ax3.autoscale(False)\n",
    "    ax3.plot(x, y, 'o', markeredgecolor='r', markerfacecolor='none', markersize=10)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "tm_results(result, imgA, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Interpret the image of the right, result of match_template function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Add the second and third occurance of A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a composed visualization function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Think about the previous results and write your conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what happen if we consider the same image but rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "\n",
    "imgA_rot=rotate(imgA, 30, resize=True, cval=1)\n",
    "\n",
    "#visualize it\n",
    "plt.imshow(imgA_rot, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(imgA_rot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = match_template(image, imgA_rot) # Uses normalized cross-correlation\n",
    "\n",
    "print(result.min(), result.max())\n",
    "print(np.unique(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how the correlation value changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_results(result, imgA_rot, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA_rot = rgb2gray(rgba2rgb(io.imread('./images/A_rotated2.png'))) \n",
    "\n",
    "plt.imshow(imgA_rot, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(imgA_rot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = match_template(image, imgA_rot) # Uses normalized cross-correlation\n",
    "\n",
    "print(result.min(), result.max())\n",
    "print(np.unique(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_results(result, imgA_rot, image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Think about the previous results and write your conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a new letter as a template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load template\n",
    "imgW = rgb2gray(rgba2rgb(io.imread('./images/W.png'))) \n",
    "\n",
    "#visualize it\n",
    "plt.imshow(imgW, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(imgA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = match_template(image, imgW) # Uses normalized cross-correlation\n",
    "\n",
    "print(result.min(), result.max())\n",
    "print(np.unique(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_results(result, imgW, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Think about the previous results. What are your conclusions now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use another image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a new image\n",
    "image = io.imread('./images/text.gif')\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgba2rgb\n",
    "\n",
    "image = rgb2gray(rgba2rgb(image))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = match_template(image, imgA) # Uses normalized cross-correlation\n",
    "\n",
    "print(result.min(), result.max())\n",
    "print(np.unique(result))\n",
    "\n",
    "\n",
    "tm_results(result, imgA, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happen with a new contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load a new image\n",
    "image = io.imread('./images/text2.gif')\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "image = rgb2gray(rgba2rgb(image))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = match_template(image, imgA) # Uses normalized cross-correlation\n",
    "\n",
    "print(result.min(), result.max())\n",
    "print(np.unique(result))\n",
    "\n",
    "\n",
    "tm_results(result, imgA, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the contrast of imgA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = match_template(image, imgA/2) # Uses normalized cross-correlation\n",
    "\n",
    "print(result.min(), result.max())\n",
    "print(np.unique(result))\n",
    "\n",
    "\n",
    "tm_results(result, imgA/2, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Think about the previous results and write your conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Change the size of imgA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rescale\n",
    "\n",
    "imgA2=rescale(imgA,.2)\n",
    "result = match_template(image, imgA2) # Uses normalized cross-correlation\n",
    "\n",
    "print(result.min(), result.max())\n",
    "print(np.unique(result))\n",
    "\n",
    "\n",
    "tm_results(result, imgA2, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Histogram of Oriented Gradients\n",
    "\n",
    "\n",
    "The [Histogram of Oriented Gradients (HOG)](https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py) feature descriptor is classical image descriptor for object detection.\n",
    "\n",
    "Check:\n",
    "- a) what is it about, and\n",
    "- b) how to construct it.\n",
    "\n",
    "Given the image 'car_template.png' and the folder 'cars', apply the HOG descriptor in order to detect where there is a car in the images in the folder 'car'. To this purpose, apply the \"sliding window\" technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the car template ('car_template.png'), obtain its HOG descriptor and visualize it. [Help](http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py) \n",
    "\n",
    "The HOG detector function is in the skimage.feature library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "fd_A, hog_A = hog(imgA, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "visualize2(imgA, hog_A, 'Input image', 'Histogram of Oriented Gradients')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "from skimage import exposure\n",
    "from skimage import transform\n",
    "\n",
    "#Reading, computing and visualizing the car example\n",
    "\n",
    "car=io.imread('./images/car_template.png')\n",
    "\n",
    "print(car.shape)\n",
    "\n",
    "fd_car, hog_car = hog(car, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "\n",
    "visualize2(car, hog_car, 'Input image', 'Histogram of Oriented Gradients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fd_car))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply the HOG descriptor on the complete set of images.\n",
    "We read images from the folder \"car\", slide a window on each image, obtain the HOG descriptor and compare to the HOG descriptor of the car template. In order to accelerate the algorithm execution, we can apply a sliding window with a step of X pixels both vertically and horizontally (e.g. X=5).\n",
    "\n",
    "Finally, we visualize the location in the image that is the most similar to the car template. Visualize the results in the following format:\n",
    "\n",
    "\n",
    "<img src=\"images/car-hog.png\" width=\"800\" height=\"100\">\n",
    "\n",
    "\n",
    "What distance will you use to compare both HOG descriptors of the car template and the image region? Compare if there is any difference in their results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code below:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def visualize_cars(car,im,im_result,pos_x,pos_y,wcar, hcar):\n",
    "        fig=plt.figure(figsize=(18,3))\n",
    "        ax1=plt.subplot(1,3,1)\n",
    "        ax2=plt.subplot(1,3,2)\n",
    "        ax3=plt.subplot(1,3,3, sharex=ax2, sharey=ax2)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title('car template')\n",
    "        ax1.imshow(car, cmap='gray')\n",
    "        ax2.set_title('best region match')\n",
    "        ax2.axis('off')\n",
    "        ax2.imshow(im, cmap='gray')\n",
    "        ax3.set_title('HOG distances')\n",
    "        ax3.axis('off')\n",
    "        ax3.imshow(im_result, cmap='gray')\n",
    "        rect2 = plt.Rectangle((pos_x-wcar/2, pos_y-hcar/2), wcar, hcar, edgecolor='r', facecolor='none')\n",
    "        rect3 = plt.Rectangle((pos_x-wcar/2, pos_y-hcar/2), wcar, hcar, edgecolor='r', facecolor='none')\n",
    "        ax2.add_patch(rect2)\n",
    "        ax3.add_patch(rect3)\n",
    "\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Computing the similarity between the car template and all the regions of the same size of the different car examples in the folder cars/\n",
    "\n",
    "def car_test():\n",
    "  ....\n",
    "\n",
    "car_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute HOG in other images to see other structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "from skimage import exposure\n",
    "from skimage import transform\n",
    "\n",
    "#Reading, computing and visualizing the car example\n",
    "\n",
    "house=rgb2gray(io.imread('./images/house.png'))\n",
    "\n",
    "fd_house, hog_house = hog(house, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "\n",
    "visualize2(house, hog_house, 'Input image', 'Histogram of Oriented Gradients')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "from skimage import exposure\n",
    "from skimage import transform\n",
    "\n",
    "#Reading, computing and visualizing the car example\n",
    "\n",
    "house=rgb2gray(io.imread('./images/house2.png'))\n",
    "\n",
    "fd_house, hog_house = hog(house, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "\n",
    "visualize2(house, hog_house, 'Input image', 'Histogram of Oriented Gradients')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:** Compare Template Matching and HOG on the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

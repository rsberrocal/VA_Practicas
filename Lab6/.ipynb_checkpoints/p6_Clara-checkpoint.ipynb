{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - P6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Delivery\n",
    "\n",
    "Up to **1 point out of 10** will be penalized if the following requirements are not fulfilled:\n",
    "\n",
    "- Implemented code should be commented.\n",
    "\n",
    "- The questions introduced in the exercises must be answered.\n",
    "\n",
    "- Add title to the figures to explain what is displayed.\n",
    "\n",
    "- Comments need to be in **english**.\n",
    "\n",
    "- The deliverable must be a file named **P6_Student1_Student2.zip** that includes:\n",
    "    - The notebook P6_Student1_Student2.ipynb completed with the solutions to the exercises and their corresponding comments.\n",
    "    - All the images used in this notebook.\n",
    "\n",
    "**Deadline (Campus Virtual): December 26, 23:59 h** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar-like features applied for face detection\n",
    "\n",
    "Today's exercices will practise the following:\n",
    "\n",
    "- Integral images and a classical use for fast harr-like feature computation.\n",
    " - Use of Adaboost for classification.\n",
    "- Decisions based on a user-defined threshold for balancing precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful imports for the exercises\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import time\n",
    "import timeit\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Build a function `to_integral_image` that computes the integral image of an input (2D) array.**\n",
    "\n",
    "The integral image must have an additional row and column full of zeros (first row and first column).\n",
    "Make sure that the values of the integral image are correct.\n",
    "\n",
    "```python\n",
    " def to_integral_image(img_arr):\n",
    "    row_sum = np.zeros(img_arr.shape)\n",
    "    integral_image_arr = np.zeros((img_arr.shape[0] + 1, img_arr.shape[1] + 1))\n",
    "    # Add here code\n",
    "    \n",
    "    return integral_image_arr\n",
    "```\n",
    "\n",
    "\n",
    "You can make the following tests:\n",
    " \n",
    " - `sum(img_array) == ii_img_array[-1,-1]`\n",
    " - `img_array[0,:].sum() == ii_img_array[1,-1]`\n",
    " \n",
    "Plot the output of the integral image for the following array:\n",
    "\n",
    "```\n",
    "img_array = np.array([[1,2,2,2,1],[1,2,2,2,1],[1,2,2,2,1],[1,2,2,2,1]])\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe9eaf62358>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_array = np.array([[1,2,2,2,1],[1,2,2,2,1],[1,2,2,2,1],[1,2,2,2,1]])\n",
    "img_array.shape\n",
    "plt.imshow(img_array, cmap=\"gray\", vmin=0, vmax= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_integral_image(img_arr):\n",
    "    \"\"\"\n",
    "    Calculates the integral image based on this instance's original image data.\n",
    "    :param img_arr: Image source data\n",
    "    :type img_arr: numpy.ndarray\n",
    "    :return Integral image for given image\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    # an index of -1 refers to the last row/column\n",
    "    # since row_sum is calculated starting from (0,0),\n",
    "    # rowSum(x, -1) == 0 holds for all x\n",
    "    row_sum = np.zeros(img_arr.shape)\n",
    "    # we need an additional column and row\n",
    "    integral_image_arr = np.zeros((img_arr.shape[0] + 1, img_arr.shape[1] + 1))\n",
    "    \n",
    "    # Iterate over rows\n",
    "    for x in range(img_arr.shape[1]):\n",
    "        # Iterate over cols\n",
    "        for y in range(img_arr.shape[0]):\n",
    "            # Sum the preview value and the actual value\n",
    "            row_sum[y, x] = row_sum[y-1, x] + img_arr[y, x]\n",
    "            #In the next value we save the value of the next column plus the actual value from row sum\n",
    "            integral_image_arr[y+1, x+1] = integral_image_arr[y+1, x] + row_sum[y, x]\n",
    "            \n",
    "    return integral_image_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe9eab32b00>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ii_img_array = to_integral_image(img_array)\n",
    "plt.imshow(ii_img_array, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Build a function to compute the sum of the pixel intensities within a rectangle using the integral image. The rectangle will be defined using the top left (x, y) and bottom right (x, y) coordinates.**\n",
    "\n",
    "Make the function with the following header:\n",
    "```\n",
    "def sum_region(integral_img_arr, top_left, bottom_right):\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_region(integral_img_arr, top_left, bottom_right):\n",
    "    ### write it!\n",
    "    # Get points\n",
    "    top, left = top_left\n",
    "    bottom, right = bottom_right    \n",
    "    \n",
    "    corner_A = integral_img_arr[top, left]\n",
    "    corner_B = integral_img_arr[top, right]\n",
    "    corner_C = integral_img_arr[bottom, left]\n",
    "    corner_D = integral_img_arr[bottom, right]\n",
    "    \n",
    "    return corner_D - corner_B - (corner_C - corner_A)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result you should get (12)\n",
    "sum_region(ii_img_array, [1,1],[3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result you should get (32)\n",
    "sum_region(ii_img_array, [0,0],[-1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3) Compute the integral image for all the following images:**\n",
    "    \n",
    "- training images of faces: save results in **`faces_ii_training`**\n",
    "- testing images of face: save the results in **`faces_ii_testing`**\n",
    "- training images of non faces: **`non_faces_ii_training`**\n",
    "- testing images of non faces:  **`non_faces_ii_testing`**\n",
    "\n",
    "To do so build a function to read all the images inside a given folder:\n",
    "\n",
    "```python\n",
    "def load_images(path):\n",
    "    images = []\n",
    "    for _file in os.listdir(path):\n",
    "       #### Read image\n",
    "       #### Remember to scale the image (wih the max pixel intensity value)\n",
    "     \n",
    "    return images\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_training_path = 'trainingdata/faces'\n",
    "neg_training_path = 'trainingdata/nonfaces'\n",
    "pos_testing_path = 'trainingdata/faces/test'\n",
    "neg_testing_path = 'trainingdata/nonfaces/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    images = []\n",
    "    # Iterate over all the files in directory\n",
    "    for file in os.listdir(path):\n",
    "        # Only take images end with png\n",
    "        if file.endswith(\".png\") :     \n",
    "            # Get image\n",
    "            img = io.imread(path + \"/\" + file)\n",
    "            # Normalize the image\n",
    "            img = img  / img.max()\n",
    "            # Get integral image and save it\n",
    "            images.append(to_integral_image(img))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_ii_training = load_images(pos_training_path) # Training faces\n",
    "faces_ii_testing = load_images(pos_testing_path) # Testing faces\n",
    "non_faces_ii_training = load_images(neg_training_path) # Training no faces\n",
    "non_faces_ii_testing = load_images(neg_testing_path) # Testing no faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faces_ii_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Compute the Haar features of an image**\n",
    "\n",
    "The code given will use the  `sum_region` function you have implemented to compute Haar-like features.\n",
    "The following code, for example, will compute a vertical Haar-like feature\n",
    "```python\n",
    "    first = sum_region(int_img, \n",
    "                      self.top_left, \n",
    "                      (self.top_left[0] + self.width, int(self.top_left[1] + self.height / 2)))\n",
    "    second = sum_region(int_img, \n",
    "                       (self.top_left[0], int(self.top_left[1] + self.height / 2)),\n",
    "                       self.bottom_right)\n",
    "    score = first - second\n",
    "```\n",
    "\n",
    "We provide you with `HaarLikeFeature` class that has build in a `get_score` function and a `get_vote` function.\n",
    "\n",
    "Your job is to \n",
    "```python\n",
    "def _create_features(img_height, img_width, min_feature_width, max_feature_width, min_feature_height, max_feature_height):\n",
    "    print('Creating Haar-like features..')\n",
    "    t0 = time.time()\n",
    "    features = []\n",
    "    for feature in FeatureTypes:\n",
    "        # FeatureTypes are just tuples\n",
    "        feature_start_width = max(min_feature_width, feature[0])\n",
    "        for feature_width in range(feature_start_width, max_feature_width, feature[0]):\n",
    "            feature_start_height = max(min_feature_height, feature[1])\n",
    "            for feature_height in range(feature_start_height, max_feature_height, feature[1]):\n",
    "                # Loop over possible x values and y values \n",
    "                # - For each (x,y) create the HarrLikeFeature objects.\n",
    "                # - append the HaarlikeFeatures in the features list.\n",
    "                # Notice that Haarlike features contain polarity, append features for polarity 1 and -1\n",
    "                # The threshold can be set to 0 for all of them.\n",
    "                \n",
    "                \n",
    "    print('\\t' + str(len(features)) + ' features created.')\n",
    "    print('\\tTime needed for calculating Harr-like features:', time.time()-t0)\n",
    "    return features\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum(**enums):\n",
    "    return type('Enum', (), enums)\n",
    "\n",
    "FeatureType = enum(TWO_VERTICAL=(1, 2), TWO_HORIZONTAL=(2, 1), THREE_HORIZONTAL=(3, 1), THREE_VERTICAL=(1, 3), FOUR=(2, 2))\n",
    "FeatureTypes = [FeatureType.TWO_VERTICAL, FeatureType.TWO_HORIZONTAL, FeatureType.THREE_VERTICAL, FeatureType.THREE_HORIZONTAL, FeatureType.FOUR]\n",
    "\n",
    "class HaarLikeFeature(object):\n",
    "    \"\"\"\n",
    "    Class representing a haar-like feature.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_type, position, width, height, threshold, polarity):\n",
    "        \"\"\"\n",
    "        Creates a new haar-like feature.\n",
    "        :param feature_type: Type of new feature, see FeatureType enum\n",
    "        :type feature_type: violajonse.HaarLikeFeature.FeatureTypes\n",
    "        :param position: Top left corner where the feature begins (x, y)\n",
    "        :type position: (int, int)\n",
    "        :param width: Width of the feature\n",
    "        :type width: int\n",
    "        :param height: Height of the feature\n",
    "        :type height: int\n",
    "        :param threshold: Feature threshold\n",
    "        :type threshold: float\n",
    "        :param polarity: polarity of the feature -1 or 1\n",
    "        :type polarity: int\n",
    "        \"\"\"\n",
    "        self.type = feature_type\n",
    "        self.top_left = position\n",
    "        self.bottom_right = (position[0] + width, position[1] + height)\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "        self.weight = 1\n",
    "    \n",
    "    def get_score(self, int_img):\n",
    "        \"\"\"\n",
    "        Get score for given integral image array.\n",
    "        :param int_img: Integral image array\n",
    "        :type int_img: numpy.ndarray\n",
    "        :return: Score for given feature\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        if self.type == FeatureType.TWO_VERTICAL:\n",
    "            first = sum_region(int_img, self.top_left, (self.top_left[0] + self.width, int(self.top_left[1] + self.height / 2)))\n",
    "            second = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 2)), self.bottom_right)\n",
    "            score = first - second\n",
    "        elif self.type == FeatureType.TWO_HORIZONTAL:\n",
    "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 2), self.top_left[1] + self.height))\n",
    "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 2), self.top_left[1]), self.bottom_right)\n",
    "            score = first - second\n",
    "        elif self.type == FeatureType.THREE_HORIZONTAL:\n",
    "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 3), self.top_left[1] + self.height))\n",
    "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 3), self.top_left[1]), (int(self.top_left[0] + 2 * self.width / 3), self.top_left[1] + self.height))\n",
    "            third = sum_region(int_img, (int(self.top_left[0] + 2 * self.width / 3), self.top_left[1]), self.bottom_right)\n",
    "            score = first - second + third\n",
    "        elif self.type == FeatureType.THREE_VERTICAL:\n",
    "            first = sum_region(int_img, self.top_left, (self.bottom_right[0], int(self.top_left[1] + self.height / 3)))\n",
    "            second = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 3)), (self.bottom_right[0], int(self.top_left[1] + 2 * self.height / 3)))\n",
    "            third = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + 2 * self.height / 3)), self.bottom_right)\n",
    "            score = first - second + third\n",
    "        elif self.type == FeatureType.FOUR:\n",
    "            # top left area\n",
    "            first = sum_region(int_img, self.top_left, (int(self.top_left[0] + self.width / 2), int(self.top_left[1] + self.height / 2)))\n",
    "            # top right area\n",
    "            second = sum_region(int_img, (int(self.top_left[0] + self.width / 2), self.top_left[1]), (self.bottom_right[0], int(self.top_left[1] + self.height / 2)))\n",
    "            # bottom left area\n",
    "            third = sum_region(int_img, (self.top_left[0], int(self.top_left[1] + self.height / 2)), (int(self.top_left[0] + self.width / 2), self.bottom_right[1]))\n",
    "            # bottom right area\n",
    "            fourth = sum_region(int_img, (int(self.top_left[0] + self.width / 2), int(self.top_left[1] + self.height / 2)), self.bottom_right)\n",
    "            score = first - second - third + fourth\n",
    "        return score\n",
    "    \n",
    "    def get_vote(self, int_img):\n",
    "        \"\"\"\n",
    "        Get vote of this feature for given integral image.\n",
    "        :param int_img: Integral image array\n",
    "        :type int_img: numpy.ndarray\n",
    "        :return: 1 iff this feature votes positively, otherwise -1\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        score = self.get_score(int_img)\n",
    "        return self.weight * (1 if score < self.polarity * self.threshold else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn(positive_iis, negative_iis, num_classifiers=-1, min_feature_width=1, max_feature_width=-1, min_feature_height=1, max_feature_height=-1):\n",
    "    \"\"\"\n",
    "    Selects a set of classifiers. Iteratively takes the best classifiers based\n",
    "    on a weighted error.\n",
    "    :param positive_iis: List of positive integral image examples\n",
    "    :type positive_iis: list[numpy.ndarray]\n",
    "    :param negative_iis: List of negative integral image examples\n",
    "    :type negative_iis: list[numpy.ndarray]\n",
    "    :param num_classifiers: Number of classifiers to select, -1 will use all\n",
    "    classifiers\n",
    "    :type num_classifiers: int\n",
    "    :return: List of selected features\n",
    "    :rtype: list[violajones.HaarLikeFeature.HaarLikeFeature]\n",
    "    \"\"\"\n",
    "    num_pos = len(positive_iis)\n",
    "    num_neg = len(negative_iis)\n",
    "    num_imgs = num_pos + num_neg\n",
    "    img_height, img_width = positive_iis[0].shape\n",
    "\n",
    "    # Maximum feature width and height default to image width and height\n",
    "    max_feature_height = img_height if max_feature_height == -1 else max_feature_height\n",
    "    max_feature_width = img_width if max_feature_width == -1 else max_feature_width\n",
    "\n",
    "    # Create initial weights and labels\n",
    "    pos_weights = np.ones(num_pos) * 1. / (2 * num_pos)\n",
    "    neg_weights = np.ones(num_neg) * 1. / (2 * num_neg)\n",
    "    weights = np.hstack((pos_weights, neg_weights))\n",
    "    labels = np.hstack((np.ones(num_pos), np.ones(num_neg) * -1))\n",
    "\n",
    "    images = positive_iis + negative_iis\n",
    "\n",
    "    # Create features for all sizes and locations\n",
    "    features = _create_features(img_height, img_width, min_feature_width, max_feature_width, min_feature_height, max_feature_height)\n",
    "    num_features = len(features)\n",
    "    feature_indexes = list(range(num_features))\n",
    "\n",
    "    num_classifiers = num_features if num_classifiers == -1 else num_classifiers\n",
    "\n",
    "    print('Calculating scores for images..')\n",
    "    t0 = time.time()\n",
    "    votes = np.zeros((num_imgs, num_features))\n",
    "    # Use as many workers as there are CPUs\n",
    "    pool = Pool(processes=None)\n",
    "    for i in range(num_imgs):\n",
    "        votes[i, :] = np.array(list(pool.map(partial(_get_feature_vote, image=images[i]), features)))\n",
    "\n",
    "    \n",
    "    print('\\tTime needed for calculating scores:', time.time()-t0)\n",
    "    \n",
    "    # select classifiers\n",
    "    classifiers = []\n",
    "\n",
    "    t0 = time.time()\n",
    "    print('Selecting classifiers..')\n",
    "    for _ in range(num_classifiers):\n",
    "\n",
    "        classification_errors = np.zeros(len(feature_indexes))\n",
    "\n",
    "        # normalize weights\n",
    "        weights *= 1. / np.sum(weights)\n",
    "\n",
    "        # select best classifier based on the weighted error\n",
    "        for f in range(len(feature_indexes)):\n",
    "            f_idx = feature_indexes[f]\n",
    "            # classifier error is the sum of image weights where the classifier\n",
    "            # is right\n",
    "            error = sum(map(lambda img_idx: weights[img_idx] if labels[img_idx] != votes[img_idx, f_idx] else 0, range(num_imgs)))\n",
    "            classification_errors[f] = error\n",
    "\n",
    "        # get best feature, i.e. with smallest error\n",
    "        min_error_idx = np.argmin(classification_errors)\n",
    "        best_error = classification_errors[min_error_idx]\n",
    "        best_feature_idx = feature_indexes[min_error_idx]\n",
    "\n",
    "        # set feature weight\n",
    "        best_feature = features[best_feature_idx]\n",
    "        feature_weight = 0.5 * np.log((1 - best_error) / best_error)\n",
    "        best_feature.weight = feature_weight\n",
    "\n",
    "        classifiers.append(best_feature)\n",
    "\n",
    "        # update image weights\n",
    "        weights = np.array(list(map(lambda img_idx: weights[img_idx] * np.sqrt((1-best_error)/best_error) if labels[img_idx] != votes[img_idx, best_feature_idx] else weights[img_idx] * np.sqrt(best_error/(1-best_error)), range(num_imgs))))\n",
    "\n",
    "        # remove feature (a feature can't be selected twice)\n",
    "        feature_indexes.remove(best_feature_idx)\n",
    "\n",
    "    print('\\tTime needed for Selecting Classifiers:', time.time()-t0,'\\n')\n",
    "\n",
    "\n",
    "    return classifiers\n",
    "\n",
    "def _get_feature_vote(feature, image):\n",
    "    return feature.get_vote(image)\n",
    "\n",
    "def _create_features(img_height, img_width, min_feature_width, max_feature_width, min_feature_height, max_feature_height):\n",
    "    \n",
    "    print('Creating Haar-like features..')\n",
    "    t0 = time.time()\n",
    "    features = []\n",
    "    for feature in FeatureTypes:\n",
    "        # FeatureTypes are just tuples\n",
    "        feature_start_width = max(min_feature_width, feature[0])\n",
    "        for feature_width in range(feature_start_width, max_feature_width, feature[0]):\n",
    "            feature_start_height = max(min_feature_height, feature[1])\n",
    "            for feature_height in range(feature_start_height, max_feature_height, feature[1]):\n",
    "                \n",
    "                # We iterate over the image (sliding window method)\n",
    "                for i in range(img_width - feature_width):\n",
    "                    for j in range(img_height - feature_height):\n",
    "                        \n",
    "                        # We get the HAAR features for both polarities\n",
    "                        feature_1 = HaarLikeFeature(feature, (i, j), feature_width, feature_height, 0, 1)\n",
    "                        feature_2 = HaarLikeFeature(feature, (i, j), feature_width, feature_height, 0, -1)\n",
    "                         \n",
    "                        # We append the new features to the \"features\" list\n",
    "                        features.append(feature_1)\n",
    "                        features.append(feature_2)\n",
    "            \n",
    "    print('\\t' + str(len(features)) + ' features created.')\n",
    "    print('\\tTime needed for calculating Harr-like features:', time.time()-t0)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)Use the learn method to learn a list of classifiers with the train data**\n",
    "\n",
    "With the `learn` function you can build a list of classifiers that detect whether an image contains a face or not.\n",
    "\n",
    "Use the following hyperparameters of the features and `num_classifiers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifiers = 2\n",
    "min_feature_height = 8\n",
    "max_feature_height = 10\n",
    "min_feature_width = 8\n",
    "max_feature_width = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Haar-like features..\n",
      "\t2496 features created.\n",
      "\tTime needed for calculating Harr-like features: 0.0062329769134521484\n",
      "Calculating scores for images..\n",
      "\tTime needed for calculating scores: 1.219994306564331\n",
      "Selecting classifiers..\n",
      "\tTime needed for Selecting Classifiers: 0.27007007598876953 \n",
      "\n",
      "CPU times: user 790 ms, sys: 49.9 ms, total: 840 ms\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We train a list of classifiers to be able to detect if an image contains a face or not\n",
    "classifiers = learn(faces_ii_training, non_faces_ii_training, num_classifiers, min_feature_width, max_feature_width, min_feature_height, max_feature_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Make a function for voting with different classifiers**\n",
    "\n",
    "Build two functions `ensemble_vote` and `ensemble_vote_all`.\n",
    "\n",
    "- `ensemble_vote(int_img, classifiers)` has to return a 1 if the majority of the votes of the classifiers is positive and a zero otherwise\n",
    "\n",
    "- `ensemble_vote_all(int_imgs, classifiers)` has to loop over the list `int_imgs` and compute the `ensemble_vote` for each image in the list. It has to return a list containing all the votes for all the images in  `int_imgs`.\n",
    "\n",
    "Use the functions to compute the train and test acurracies for faces and non faces.\n",
    "\n",
    "Print the results in the following format:\n",
    "```\n",
    "train results:\n",
    "Correctly identified Faces: 2129/2429  (87.64923836969946%)\n",
    "Correctly identified non-Faces: 4276/8548  (50.02339728591484%)\n",
    "\n",
    "test results:\n",
    "Correctly identified Faces: 300/472  (63.559322033898304%)\n",
    "Correctly identified non-Faces: 74/128  (57.8125%)\n",
    "```\n",
    "\n",
    "It is not required to get this exact results but print the information in this format. It facilitates understanding the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_vote(int_img, classifiers):\n",
    "    \n",
    "    # We get the votes for every classifier in \"classifiers\"\n",
    "    votes = [classifier.get_vote(int_img) for classifier in classifiers]\n",
    "    \n",
    "    # We count the positive and negative votes\n",
    "    num_pos, num_neg = 0, 0\n",
    "    for vote in votes:\n",
    "        \n",
    "        if vote > 0:\n",
    "            num_pos += 1\n",
    "        else:\n",
    "            num_neg += 1\n",
    "            \n",
    "    # If the majority of all votes is positive, we return 1\n",
    "    if num_pos > num_neg:\n",
    "        return 1\n",
    "    \n",
    "    # Otherwise, we return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_vote_all(int_imgs, classifiers):\n",
    "\n",
    "    # We return a list containing all ensemble_vote values for each image in \"int_imgs\"\n",
    "    return [ensemble_vote(img, classifiers) for img in int_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the training and the testing images in a dictionary called \"img_collections\"\n",
    "img_collections = {\"train\" : (faces_ii_training, non_faces_ii_training),\n",
    "                  \"test\" : (faces_ii_testing, non_faces_ii_testing)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"compute_accuracies\" function takes an image collection\n",
    "# and the trained classifiers as parameters.\n",
    "\n",
    "# It returns the accuracies for face and non-face in the train \n",
    "# and the test image collections.\n",
    "\n",
    "def compute_accuracies(img_collections, classifiers):\n",
    "    \n",
    "    # We take the name (\"name\") and the image collection's images (\"(faces_ii_..., non_faces_ii_...)\")\n",
    "    for name, images in img_collections.items():\n",
    "        \n",
    "        # We get the votes for the \"faces\"\n",
    "        votes_1 = ensemble_vote_all(images[0], classifiers)\n",
    "        # We get the votes for the \"non_faces\"\n",
    "        votes_2 = ensemble_vote_all(images[1], classifiers)\n",
    "        \n",
    "        # We count the votes for the \"faces\"\n",
    "        count_votes_1 = votes_1.count(1)\n",
    "         # We count the votes for the \"non_faces\"\n",
    "        count_votes_2 = votes_2.count(0)\n",
    "        \n",
    "        # We calculate the percentage of \"faces\"\n",
    "        percentage_1 = count_votes_1 * 100 / len(votes_1)\n",
    "        # We calculate the percentage of \"non_faces\"\n",
    "        percentage_2 = count_votes_2 * 100 / len(votes_2)\n",
    "        \n",
    "        # We print the results\n",
    "        print(f\"{name} results:\")\n",
    "        print(f\"Correctly identified Faces: {count_votes_1}/{len(votes_1)}  ({percentage_1}%)\")\n",
    "        print(f\"Correctly identified Non-Faces: {count_votes_2}/{len(votes_2)}  ({percentage_1}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results:\n",
      "Correctly identified Faces: 37/39  (94.87179487179488%)\n",
      "Correctly identified Non-Faces: 25/29  (94.87179487179488%)\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 17/30  (56.666666666666664%)\n",
      "Correctly identified Non-Faces: 13/20  (56.666666666666664%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compute_accuracies(img_collections, classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Make another test with 20 classifiers instead of 2**\n",
    "\n",
    "Inspect the classification results if you use adaboost with 20 classifiers. Use the same hyperameters for the features.\n",
    "Print the results as in the previous exercise:\n",
    "\n",
    "```\n",
    "train results:\n",
    "Correctly identified Faces: 2256/2429  (92.87772745986003%)\n",
    "Correctly identified non-Faces: 7046/8548  (82.42863827795975%)\n",
    "\n",
    "test results:\n",
    "Correctly identified Faces: 285/472  (60.381355932203384%)\n",
    "Correctly identified non-Faces: 104/128  (81.25%)\n",
    "```\n",
    "\n",
    "- Do the classification results improved in the train data? Yes, we now get a 100% of accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifiers = 20\n",
    "min_feature_height = 8\n",
    "max_feature_height = 10\n",
    "min_feature_width = 8\n",
    "max_feature_width = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Haar-like features..\n",
      "\t2496 features created.\n",
      "\tTime needed for calculating Harr-like features: 0.0050048828125\n",
      "Calculating scores for images..\n",
      "\tTime needed for calculating scores: 1.2405338287353516\n",
      "Selecting classifiers..\n",
      "\tTime needed for Selecting Classifiers: 2.5934526920318604 \n",
      "\n",
      "CPU times: user 2.95 s, sys: 86.8 ms, total: 3.04 s\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifiers_20 = learn(faces_ii_training, non_faces_ii_training, num_classifiers, min_feature_width, max_feature_width, min_feature_height, max_feature_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results:\n",
      "Correctly identified Faces: 39/39  (100.0%)\n",
      "Correctly identified Non-Faces: 29/29  (100.0%)\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 19/30  (63.333333333333336%)\n",
      "Correctly identified Non-Faces: 11/20  (63.333333333333336%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compute_accuracies(img_collections, classifiers_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Change the voting functions so that you can set a threshold for deciding a prediction**\n",
    "\n",
    "The threshold value indicates the minimum score for assigning a \"positive\" label (detect a face).\n",
    "\n",
    "Create the following functions\n",
    "\n",
    "- `ensemble_vote_t`: returns the final decision of a list of classifiers for a given threshold.\n",
    "- `ensemble_vote_all_t`: Iterates over a list of integral images and returns the  final decision of a list of classifiers for each of the images (for a given threshold).\n",
    "\n",
    "\n",
    "\n",
    "compute the following:\n",
    "\n",
    "- a) number of correct faces over all faces (in the train data)\n",
    "- b) number of correct non faces over all non faces (in the train data)\n",
    "- c) number of correct faces over all faces (in the test data)\n",
    "- d) number of correct non faces over all non faces (in the test data)\n",
    "\n",
    "Using the list of 20 classifiers.\n",
    "\n",
    "\n",
    "The quantities have to be computed for each of the following thresholds:\n",
    "\n",
    "```\n",
    "thresholds = np.array([x for x in range(-5,5,1)])/10.\n",
    "```\n",
    "\n",
    "- Make a bar bar plot for a) b) c) and d). In the x axis write the threshold value. \n",
    "\n",
    "- What happens when you increase the threshold value? We get correctly identified less faces but more non_faces with both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.array([x for x in range(-5,5,1)])/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_faces_train_t = []\n",
    "correct_non_faces_train_t = []\n",
    "correct_faces_test_t = []\n",
    "correct_non_faces_test_t = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_score(int_img, classifiers):\n",
    "    \n",
    "    return sum([c.get_vote(int_img) for c in classifiers])\n",
    "\n",
    "def ensemble_vote_t(int_img, classifiers,t):\n",
    "    \n",
    "    # We get the score for the \"int_img\"\n",
    "    score = ensemble_score(int_img, classifiers)\n",
    "    \n",
    "    # We return True if the score is higher than our threshold\n",
    "    return score > t\n",
    "\n",
    "def ensemble_vote_all_t(int_imgs, classifiers,t=-0.1):\n",
    "    \n",
    "    # We get the votes for all images in \"int_imgs\"\n",
    "    votes = [ensemble_vote_t(img, classifiers, t) for img in int_imgs]\n",
    "    \n",
    "    # We return them\n",
    "    return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracies_t(img_collections, classifiers, t):\n",
    "    \n",
    "    # \"values\" is the list where we're going to save the number \n",
    "    # of votes for \"faces\" and \"no_faces\" for both training and testing images\n",
    "    values = {}\n",
    "    \n",
    "    # We take the name (\"name\") and the image collection's images (\"(faces_ii_..., non_faces_ii_...)\")\n",
    "    for name, images in img_collections.items():\n",
    "        \n",
    "        # We get the votes for the \"faces\" using the threshold\n",
    "        votes_1 = ensemble_vote_all_t(images[0], classifiers, t)\n",
    "        # We get the votes for the \"non_faces\" using the threshold\n",
    "        votes_2 = ensemble_vote_all_t(images[1], classifiers, t)\n",
    "        \n",
    "        # We count the votes for the \"faces\"\n",
    "        count_votes_1 = votes_1.count(True)\n",
    "        # We count the votes for the \"non_faces\"\n",
    "        count_votes_2 = votes_2.count(False)\n",
    "        \n",
    "        # We print the results\n",
    "        print(f\"{name} results:\")\n",
    "        print(f\"Correctly identified Faces: {count_votes_1}/{len(votes_1)}\")\n",
    "        print(f\"Correctly identified Non-Faces: {count_votes_2}/{len(votes_2)}\\n\")\n",
    "        \n",
    "        # We append the results to \"values\"\n",
    "        values[name] = (count_votes_1, count_votes_2)\n",
    "    \n",
    "    # We return the list containing the results\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results:\n",
      "Correctly identified Faces: 39/39\n",
      "Correctly identified Non-Faces: 29/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 25/30\n",
      "Correctly identified Non-Faces: 8/20\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': (39, 29), 'test': (25, 8)}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracies_t(img_collections, classifiers_20, -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train results:\n",
      "Correctly identified Faces: 39/39\n",
      "Correctly identified Non-Faces: 10/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 30/30\n",
      "Correctly identified Non-Faces: 0/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 39/39\n",
      "Correctly identified Non-Faces: 10/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 30/30\n",
      "Correctly identified Non-Faces: 0/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 39/39\n",
      "Correctly identified Non-Faces: 10/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 30/30\n",
      "Correctly identified Non-Faces: 0/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 39/39\n",
      "Correctly identified Non-Faces: 10/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 30/30\n",
      "Correctly identified Non-Faces: 0/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 38/39\n",
      "Correctly identified Non-Faces: 18/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 29/30\n",
      "Correctly identified Non-Faces: 5/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 38/39\n",
      "Correctly identified Non-Faces: 18/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 29/30\n",
      "Correctly identified Non-Faces: 5/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 38/39\n",
      "Correctly identified Non-Faces: 18/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 29/30\n",
      "Correctly identified Non-Faces: 5/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 37/39\n",
      "Correctly identified Non-Faces: 25/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 17/30\n",
      "Correctly identified Non-Faces: 13/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 37/39\n",
      "Correctly identified Non-Faces: 25/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 17/30\n",
      "Correctly identified Non-Faces: 13/20\n",
      "\n",
      "train results:\n",
      "Correctly identified Faces: 37/39\n",
      "Correctly identified Non-Faces: 25/29\n",
      "\n",
      "test results:\n",
      "Correctly identified Faces: 17/30\n",
      "Correctly identified Non-Faces: 13/20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_accuracies_t = [compute_accuracies_t(img_collections, classifiers, t) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'train': (39, 10), 'test': (30, 0)}, {'train': (39, 10), 'test': (30, 0)}, {'train': (39, 10), 'test': (30, 0)}, {'train': (39, 10), 'test': (30, 0)}, {'train': (38, 18), 'test': (29, 5)}, {'train': (38, 18), 'test': (29, 5)}, {'train': (38, 18), 'test': (29, 5)}, {'train': (37, 25), 'test': (17, 13)}, {'train': (37, 25), 'test': (17, 13)}, {'train': (37, 25), 'test': (17, 13)}]\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We prepare the lists that will contain the values to plot\n",
    "faces_train_t = [dct[\"train\"][0] for dct in all_accuracies_t]\n",
    "non_faces_train_t = [dct[\"train\"][1] for dct in all_accuracies_t]\n",
    "faces_test_t = [dct[\"test\"][0] for dct in all_accuracies_t]\n",
    "non_faces_test_t = [dct[\"test\"][1] for dct in all_accuracies_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We show the different bar plots\n",
    "\n",
    "fig = plt.figure(figsize = (15, 12)) \n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax = plt.bar(thresholds, faces_train_t, color ='orange', width = 0.05) \n",
    "plt.xlabel(\"Thresholds\") \n",
    "plt.ylabel(\"Correctly identified faces\") \n",
    "plt.title(\"Train\")\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax = plt.bar(thresholds, non_faces_train_t, color ='red', width = 0.05) \n",
    "plt.xlabel(\"Thresholds\") \n",
    "plt.ylabel(\"Correctly identified non-faces\") \n",
    "plt.title(\"Train\")\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax = plt.bar(thresholds, faces_test_t, color ='orange', width = 0.05) \n",
    "plt.xlabel(\"Thresholds\") \n",
    "plt.ylabel(\"Correctly identified faces\") \n",
    "plt.title(\"Test\")\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "ax = plt.bar(thresholds, non_faces_test_t, color ='red', width = 0.05) \n",
    "plt.xlabel(\"Thresholds\") \n",
    "plt.ylabel(\"Correctly identified non_faces\") \n",
    "plt.title(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition\n",
    "\n",
    "1. Define an appropiate representation\n",
    "\n",
    "2. Train a classifier \n",
    "\n",
    "3. Recognize a new face example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Build a new reduced space applying a PCA to the faces and non faces images**\n",
    "\n",
    "Remember we have the following images:\n",
    "\n",
    "- training images of faces\n",
    "- testing images of face\n",
    "- training images of non faces\n",
    "- testing images of non faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_no_integral(path):\n",
    "    images = []\n",
    "    # Iterate over all the files in directory\n",
    "    for file in os.listdir(path):\n",
    "        # Only take images end with png\n",
    "        if file.endswith(\".png\") :     \n",
    "            # Get image\n",
    "            img = io.imread(path + \"/\" + file)            \n",
    "            # save image\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 19, 19)\n",
      "19 19\n"
     ]
    }
   ],
   "source": [
    "# Loading images\n",
    "faces_training = load_images_no_integral(pos_training_path) # Training faces\n",
    "faces_testing = load_images_no_integral(pos_testing_path) # Testing faces\n",
    "non_faces_training = load_images_no_integral(neg_training_path) # Training no faces\n",
    "non_faces_testing = load_images_no_integral(neg_testing_path) # Testing no faces\n",
    "\n",
    "X_train = np.array(faces_training + non_faces_training)\n",
    "X_test = np.array(faces_testing + non_faces_testing)\n",
    "\n",
    "y_train = np.array([1] * len(faces_training) + [0] * len(non_faces_training)) # Labels face = 1, non face = 0\n",
    "y_test = np.array([1] * len(faces_testing) + [0] * len(non_faces_testing)) # Labels face = 1, non face = 0\n",
    "\n",
    "nsamples, h, w = X_train.shape\n",
    "print(X_test.shape)\n",
    "print(h, w)\n",
    "\n",
    "def reshapeData(data):\n",
    "    nsamples, h, w = data.shape\n",
    "    new_data = data.reshape((nsamples,h*w))\n",
    "    return new_data\n",
    "\n",
    "# Reshape X_train\n",
    "X_train = reshapeData(X_train)\n",
    "\n",
    "# Reshape X_test\n",
    "X_test = reshapeData(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 40\n",
    "# compute PCA\n",
    "pca = PCA(n_components = n_components).fit(X_train)\n",
    "\n",
    "# apply tranformation\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Train a classifier from a set of example**\n",
    "\n",
    "Train a adaboost classifier using the new PCA subspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non Face       0.37      0.80      0.51        20\n",
      "        Face       0.43      0.10      0.16        30\n",
      "\n",
      "    accuracy                           0.38        50\n",
      "   macro avg       0.40      0.45      0.34        50\n",
      "weighted avg       0.41      0.38      0.30        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report # to visualize the classification results\n",
    "\n",
    "# AdaBoostClassifier using the PCA data\n",
    "ada_model_pca = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "# Fit AdaBoost\n",
    "ada_model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred_pca = ada_model_pca.predict(X_test_pca)\n",
    "\n",
    "score_pca = ada_model_pca.score(X_test_pca, y_test)\n",
    "# Non Face will be 0, Face will be 1\n",
    "target_names = ['Non Face', 'Face']\n",
    "\n",
    "print(classification_report(y_test, y_pred_pca, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Recognize a new examples**\n",
    "\n",
    "Proyect the new face examples (test set) in the learned model. Plot the image with the prediction of the model and the real label.\n",
    "\n",
    "<img src=\"notebook_images/prediction.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function will plot all\n",
    "def plot_gallery(images, titles, h, w, rows=3, cols=4):\n",
    "    # Struct\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    # Plot every image\n",
    "    for i in range(rows * cols):\n",
    "        # Create subplot\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        # Plot image\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap='gray')\n",
    "        plt.title(titles[i])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-09a9585e1ca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m'predicted: {0}\\ntrue: {1}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprediction_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplot_gallery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Save prediction and true label\n",
    "# Plot the results\n",
    "def predict(y_pred, y_test, target_names):\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        pred_name = target_names[y_pred[i]]    \n",
    "        true_name = target_names[y_test[i]]\n",
    "\n",
    "        yield 'predicted: {0}\\ntrue: {1}'.format(pred_name, true_name)\n",
    "\n",
    "prediction_titles = list(predict(y_pred, y_test, target_names))\n",
    "plot_gallery(X_test, prediction_titles, h, w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
